{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0ce090",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfffde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "file = pathlib.Path('probing-training-generic-names.json')\n",
    "with file.open('r') as handle:\n",
    "    samples = json.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47cb65",
   "metadata": {},
   "source": [
    "Load the model and precompute the representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba0de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = transformers.AutoModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9136ded3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8785ccb182424193cd50562f6cca8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "loader = data.DataLoader(samples, batch_size=32)\n",
    "precomputed = []\n",
    "for batch in tqdm(loader):\n",
    "    inputs = tokenizer(batch['text'], return_tensors='pt', padding='longest').to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "        reps = outputs.hidden_states[-1][range(len(batch['text'])), batch['token']]\n",
    "    precomputed.append(reps)\n",
    "precomputed = torch.cat(precomputed)\n",
    "precomputed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867cc41b",
   "metadata": {},
   "source": [
    "Train the probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aca39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "PATIENCE = 4\n",
    "HOLD_OUT = .05\n",
    "EXCLUDE = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073323ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, samples, precomputed):\n",
    "        self.samples = samples\n",
    "        self.precomputed = precomputed\n",
    "        \n",
    "        indexer = {}\n",
    "        for sample in samples:\n",
    "            label = sample['label']\n",
    "            if label not in indexer:\n",
    "                indexer[label] = len(indexer)\n",
    "        self.indexer = indexer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        rep = self.precomputed[index]\n",
    "        return rep, self.indexer[sample['label']]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "dataset = Dataset(samples, precomputed)\n",
    "\n",
    "exclude_size = int(EXCLUDE * len(dataset))\n",
    "val_size = int(HOLD_OUT * len(dataset))\n",
    "train_size = len(dataset) - val_size - exclude_size\n",
    "train, val, exclude = data.random_split(dataset, (train_size, val_size, exclude_size))\n",
    "\n",
    "train_loader = data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = data.DataLoader(val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f580403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8166275084e245f086245e4899e47c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train probe:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "probe = nn.Sequential(\n",
    "    nn.Linear(768, 768),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(768, len(dataset.indexer)),\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(probe.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "progress = tqdm(range(EPOCHS), desc='train probe')\n",
    "best, bad, state_dict = float('inf'), 0, None\n",
    "for epoch in progress:\n",
    "    train_loss = 0.\n",
    "    for reps, targets in train_loader:\n",
    "        predictions = probe(reps)\n",
    "        loss = criterion(predictions, targets.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    val_loss = 0.\n",
    "    with torch.inference_mode():\n",
    "        for reps, targets in val_loader:\n",
    "            predictions = probe(reps)\n",
    "            loss = criterion(predictions, targets.to(device))\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    progress.set_description(f'train probe (train={train_loss:.3f}, val={val_loss:.3f})')\n",
    "\n",
    "    if val_loss < best:\n",
    "        state_dict = probe.state_dict()\n",
    "        best = val_loss\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "\n",
    "    if bad > PATIENCE:\n",
    "        probe.load_state_dict(state_dict)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ec4181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc84eeea765c4be5ab0272e34b76a68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9777, device='cuda:1')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae90f92cc38947889168145b4454cd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9798, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "@torch.inference_mode()\n",
    "def test(dataset):\n",
    "    loader = data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "    correct = 0\n",
    "    for reps, targets in tqdm(loader):\n",
    "        predictions = probe(reps).argmax(dim=-1)\n",
    "        correct += predictions.view(len(reps)).eq(targets.to(device).view(len(reps))).sum()\n",
    "    return correct / len(dataset)\n",
    "\n",
    "print(test(val))\n",
    "print(test(exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8881f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'john', 'has', 'patients', '.', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['judge', 'theologian', 'psychiatrist', 'physician', 'officer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict(text, tokens=[1]):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding='longest').to(device)\n",
    "    print(tokenizer.convert_ids_to_tokens(inputs.input_ids.squeeze().tolist()))\n",
    "    outputs = model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "    reps = outputs.hidden_states[-1][:, tokens].mean(dim=1)\n",
    "    chosens = probe(reps).topk(k=5, dim=-1).indices.squeeze().tolist()\n",
    "    unindexer = {idx: label for label, idx in dataset.indexer.items()}\n",
    "    return [unindexer[chosen] for chosen in chosens]\n",
    "predict('John has patients.', tokens=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c41b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(probe, 'probe_wikidata_occupation.pth')\n",
    "#torch.save(dataset.indexer, 'probe_wikidata_occupation_indexer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb51a285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['editor', 'tarento', 'field hockey player', 'psychiatrist', 'educator', 'sportsperson', 'linguist', 'seiyÅ«', 'herpetologist', 'mathematician', 'art historian', 'australian rules footballer', 'translator', 'artistic gymnast', 'opera singer', 'zoologist', 'ice hockey player', 'rabbi', 'boxer', 'music educator', 'fencer', 'screenwriter', 'television presenter', 'biathlete', 'physicist', 'beauty pageant contestant', 'geologist', 'sculptor', 'basketball player', 'motorcycle racer', 'musicologist', 'rugby league player', 'alpine skier', 'association football referee', 'musician', 'aviator', 'judge', 'officer', 'head coach', 'businessperson', 'monk', 'journalist', 'rugby union player', 'trade unionist', 'athletics competitor', 'illustrator', 'racecar driver', 'priest', 'non-fiction writer', 'sport cyclist', 'sport shooter', 'author', 'archaeologist', 'judoka', 'sociologist', 'golfer', 'av idol', 'photographer', 'guitarist', 'university teacher', 'police officer', 'economist', 'diplomat', 'surgeon', 'painter', 'architect', 'entomologist', 'pianist', 'cleric', 'cricketer', 'amateur wrestler', 'american football player', 'theatre director', 'volleyball player', 'missionary', 'singer-songwriter', 'film director', 'explorer', \"children's writer\", 'writer', 'banker', 'table tennis player', 'choreographer', 'comedian', 'comics artist', 'mixed martial artist', 'catholic priest', 'farmer', 'figure skater', 'anthropologist', 'film producer', 'swimmer', 'stage actor', 'diver', 'mangaka', 'songwriter', 'baseball player', 'historian', 'yachtmaster', 'psychologist', 'voice actor', 'composer', 'conductor', 'film actor', 'biologist', 'singer', 'samurai', 'engineer', 'record producer', 'entrepreneur', 'handball player', 'association football manager', 'association football player', 'radio personality', 'minister', 'playwright', 'racing driver', 'physician', 'theologian', 'model', 'speed skater', 'television actor', 'computer scientist', 'philosopher', 'soldier', 'actor', 'basketball coach', 'rower', 'sprinter', 'lawyer', 'badminton player', 'poet', 'cinematographer', 'tennis player', 'literary critic', 'novelist', 'chemist', 'politician', 'teacher', 'artist', 'jurist', 'astronomer', 'chess player', 'visual artist', 'military personnel', 'canoer', 'publisher', 'jazz musician', 'botanist', 'announcer'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.indexer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159d46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
